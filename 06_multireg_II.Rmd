# Multiple Regression II: Qualitative Variablen einbinden {#reg2}

## üì¢ Zielsetzung dieser Einheit {.unnumbered}

In dieser Einheit wird die Nutzung qualitativer - also nominal oder ordinal skalierter - Variablen in Regressionsmodellen anhand des Beispiel zur Erkl√§rung der bezirksweisen Impfquoten aus Einheit \@ref(reg1) behandelt.

```{r echo=FALSE, purl=FALSE}
# myScriptname <- tools::file_path_sans_ext(tail(strsplit(rstudioapi::getSourceEditorContext()$path, "/")[[1]], 1))
myScriptname <- "06_multireg_II"

knitr::asis_output(paste(
  "<p><strong>tl;dr: </strong>",
  "<a href=\"https://kamihoeferl.at/lehre/vu_sozwiss_2/",
  myScriptname,
  ".R\" type=\"application/octet-stream\">Her mit dem Code!</a></p>",
  sep = ""))
```

------------------------------------------------------------------------

## Ouvert√ºre

Wie in Einheit \@ref(reg1) nutzen wir erneut den Datensatz zu den bezirksweiten Impfquoten (Stand 24.10.21). In diesem Datensatz wurden mehrere Teildatens√§tze miteinander verkn√ºpft. Eine genaue Beschreibung dieser Teildatens√§tze findet sich in Kapitel \@ref(ouvert-reg1). Diese Teildatens√§tze wurden in einer Excel-Datei gesammelt, mittels Aggregation auf die einheitliche Bezugsebene der politischen Bezirke gebracht und im Tabellenblatt "ex" miteinander verkn√ºpft.

[**üö© Die Excel-Datei kann hier heruntergeladen werden üö©**](data/corona_bez_regression_v1.xlsx)

> **üëâ Anmerkung**: Wir gehen in dieser Einheit von folgender Verzeichnisstruktur aus:

    **Projektfolder**
    | skript_1.R
    | ...
    | skript_n.R    
    +-- data
    |     | datensatz_1.xyz
    |     | ...
    |     | datensatz_n.xyz
    +-- output

## Gedankliche Modellbildung

In der vorigen Einheit konnten wir in Kapitel \@ref(map-impfquoten) einen ersten √úberblick auf die r√§umliche Verteilung der bezirksweisen Impfquoten gewinnen:

![Anteil der Immunisierten in den √∂sterreichischen Bezirken (Stand: Oktober 2021)](images/choropleth2-1.png)

Dabei sehen wir, dass vor allem die Bundesl√§nder Salzburg, Ober√∂sterreich und K√§rnten mit niedrigen und das Burgenland sowie Teile Nieder√∂sterreichs und der Steiermark mit hohe Impfquoten aufweisen. Wir wollen daher **√ºberpr√ºfen**, ob die **Hinzunahme der "Bundeslandzugeh√∂rigkeit"** unser Regressionsmodell (vgl. Kapitel \@ref(reg1))

a\) hinsichtlich der **Varianzaufkl√§rung** verbessert;

b\) und zu Ver√§nderungen in den **Regressionsparametern** f√ºhrt.

Folgender **Workflow** bietet sich dazu an

1.  Wir importieren die *Ausgangsdaten*;

2.  ermitteln die *Bundeslandzugeh√∂rigkeit* der Bezirke;

3.  erg√§nzen unser *Regressionsmodell* um diese Zugeh√∂rigkeit;

4.  und pr√ºfen, ob wir damit die *Annahmen* linearer Modelle erf√ºllen.

## Daten importieren

√úber das **readxl-Package** laden wir zun√§chst die Daten aus dem Tabellenblatt "ex":

```{r, message=FALSE, warning=FALSE, results="hide"}
library(readxl)     # Excel-Dateien lesen
library(tidyverse)  # https://www.tidyverse.org/packages/

daten <- read_excel("data/corona_bez_regression_v1.xlsx", sheet = "ex")
```

Damit erhalten wir den bekannten Datensatz zu den bezirksweisen Impfquoten zum Stand Oktober 2021:

```{r}
head(daten)
```

## Die Bundeslandzugeh√∂rigkeit der Bezirke ermitteln

Zu welchem Bundesland ein Bezirk geh√∂rt, k√∂nnen wir in zwei Schritten ermitteln:

1.  Zun√§chst extrahieren wir aus der Bezirkskennzahl "bez_id" das jeweilige **Bundesland**. Wir erinnern uns: Die [erste Stelle der Bezirkskennzahl](http://www.statistik.at/web_de/klassifikationen/regionale_gliederungen/politische_bezirke/index.html) steht f√ºr das jeweilige Bundesland.

```{r}
daten <- daten %>%
  mutate(bld = floor(bez_id/100))
```

2.  Um das nominale Skalenniveau dieser Bundeslandzugeh√∂rigkeit auch noch korrekt abzubilden, √ºberf√ºhren wir die Variable "bld" in einen **Faktor**. Um dabei zu wissen, welche Zahl f√ºr welches Bundesland steht: Die Verwaltungseinheiten werden dazu in √ñsterreich immer [**alphabetisch aufsteigend** sortiert und nummeriert](http://www.statistik.at/web_de/klassifikationen/regionale_gliederungen/politische_bezirke/index.html).

```{r}
daten <- daten %>%
  mutate(bld = factor(bld, labels = c("Bgld.", "Ktn.", "N√ñ", "O√ñ",
                                      "Sbg.", "Stmk.", "T", "Vbg.", "W")))
head(daten$bld)
```

Damit bleibt uns nur mehr, den Datensatz f√ºr die weitere Analyse etwas **auszud√ºnnen** - also nicht ben√∂tigte Variablen und Records (vgl. Kapitel \@ref(referenzmodell)) zu entfernen:

```{r}
sel_daten <- daten %>%
  filter(bez_id <= 900 & bez_id != 709) %>%
  select(bez_id, bez_txt, bld, anteil_immun, tote_100k, bev_anteil_65plus,
         anteil_noaut, bildung_anteil_hochschule, nrw19_anteil_fpoe)
```

## Qualitative Variablen in Regressionsmodellen nutzen {#qualVaria}

Prinzipiell k√∂nnen qualitative - also nominal und ordinal skalierte - Variablen in Regressionsmodellen ber√ºcksichtigt werden. Man sollte aber folgende zwei Punkte nicht aus den Augen verlieren:

-   **Regressionsanalyse** misst den Einfluss einer oder mehrerer quantitativer unabh√§ngiger auf eine quantitative abh√§ngige Variable (vgl. Kapitel 1 in \@Backhaus2018). Mit ihr kann beispielsweise der Einfluss der K√∂rpergr√∂√üe auf das Gewicht einer Person untersucht werden.\
    Qualitative Variablen k√∂nnen als sgn. **Dummy-Variablen** ber√ºcksichtigt werden, sollten jedoch nicht den √ºberwiegenden Teil der unabh√§ngigen Variablen stellen.
-   **Varianzanalyse** misst den Einfluss qualitativer unabh√§ngiger Variablen auf eine quantitative abh√§ngige Variable (vgl. Kapitel 3 in \@Backhaus2018). Mit ihr kann beispielsweise der Einfluss des Geschlechts auf Einkommen einer Person untersucht werden. Analog zur Regressionsanalyse k√∂nnen dabei auch quantitative Variablen (als sgn. "Kovariaten") ber√ºcksichtigt werden; sie sollten aber nicht den √ºberwiegenden Teil der unabh√§ngigen Variablen stellen.

Wir entscheiden uns, das bestehende Regressionsmodell zu erweitern und m√ºssen daf√ºr die Bundeslandzugeh√∂rigkeit in sgn. **Dummy-Codes** √ºberf√ºhren. Dazu wird jede Merkmalsauspr√§gung D einer qualitativen Variable in einer logischen Variable (bin√§r) abgebildet:

$$
D=\begin{cases}
    1 & \text{Merkmal vorhanden} \\
    0 & \text{Merkmal nicht vorhanden}
  \end{cases}
$$

Gl√ºcklicherweise √ºberf√ºhrt R Faktoren in Regressionsmodellen automatisch in Dummy-Codes.

> **üìö Exkurs: Dummy-Codes from the inside**
>
> Um diese Dummy-Codes etwas besser zu verstehen, werfen wir zun√§chst einen Blick auf die Levels des Faktors Bundesland:

```{r Levels bld}
levels(sel_daten$bld)
```

> Diese neun Merkmalsauspr√§gungen werden von R automatisch in n-1 (sprich: Enminuseeeeins mit n = Anzahl der Faktor-Levels), also 8 Dummy-Variablen √ºberf√ºhrt:

```{r Auto-Dummy-Codes anzeigen}
model.matrix(~ bld, sel_daten) %>%  # Dummy-Coding liefert ...
  .[,-1] %>%        # ... eine Matrix ...
  as_tibble() %>%   # ... die ein einen Tibble √ºberf√ºhrt wird ...
  bind_cols(sel_daten[c("bez_txt", "bld")], .) %>%  # ... der noch einleitende Spalten bekommt
  head()
```

> Am Bezirk Eisenstadt (Stadt) sehen wir, dass alle acht vergebenen Dummy-Codes 0 entsprechen.
>
> **ü§î Kann das stimmen?**
>
> Jep, da wir ja nur n-1 Dummy-Codes nutzen um die Bundeslandzugeh√∂rigkeiten der Bezirke abzubilden. Im Fall von Eisenstadt (Stadt) hei√üt das, dass sich R dazu entschieden hat, das erste Level des Faktors "bld" (= "Bgld.") als [Linearkombination](https://de.wikipedia.org/wiki/Linearkombination) der restlichen acht Levels dieses Faktors zu interpretieren. Die Logik dahinter: Wenn ein Bezirk nicht zu den acht Bundesl√§nder K√§rnten bis Wien geh√∂rt, muss er zwangsweise ein burgenl√§ndischer Bezirk sein.\
> Inhaltlich spielt es keine Rolle, welches Level eines Faktors als Linearkombination interpretiert wird. Jedoch: Bei der Interpretation der Regressionsparameter ist es wichtig zu wissen, welches Level eines Faktors als Linearkombination abgebildet wurde. Mehr dazu gleich ...

## Der Einflu√ü des Bundeslandes auf die Impfquote

Kommen wir nun zur eigentlichen Modellbildung. Dazu werden wir **folgende Schritte** durchlaufen:

1.  Wir *standardisieren* die metrischen Variablen in unserem Datensatz, um die Vergleichbarkeit der Regressionsparameter sicherzustellen;
2.  Wir *reproduzieren* das in Einheit \@ref(reg1) optimierte *Regressionsmodell (lm0)*, um Vergleichswerte zur Varianzaufkl√§rung und der Regressionsparameter zu erhalten ;
3.  Wir bilden ein *neues Regressionsmodell (lm1)*, das die Bundeslandzugeh√∂rigkeit der Bezirke ber√ºcksichtigt;
4.  *optimieren* dieses (lm2 & lm3);
5.  und *vergleichen* dieses neue Modell mit dem im Schritt 2 ermittelten Referenzmodell (aus Einheit \@ref(reg1)).

### Standardisieren der metrischen Variablen

Analog zu Kapitel \@ref(ztrans) nutzen wir hierzu eine Z-Transformation:

```{r Vars standardisieren}
sel_daten_trans <- sel_daten %>%
  mutate(across(c("anteil_immun", "tote_100k", "bev_anteil_65plus",
         "anteil_noaut", "bildung_anteil_hochschule", "nrw19_anteil_fpoe"),scale))
```

### Reproduktion unseres Referenzmodells aus Einheit \@ref(reg1)

Dazu greifen wir auf das in Kapitel \@ref(referenzmodell) formulierte Modell zur√ºck:

```{r lm0 ohne bld}
lm0 <- lm(anteil_immun ~ tote_100k + bev_anteil_65plus + anteil_noaut 
          + bildung_anteil_hochschule, data = sel_daten_trans)
summary(lm0)
```

### Erweiterung des Modells um die Bundeslandzugeh√∂rigkeit der Bezirke

Da R die **Dummy-Codierung des Faktors bld** automatisch vornimmt, k√∂nnen wir diesen einfach zur Modellgleichung hinzuf√ºgen:

```{r lm1 mit bld und noSZ}
lm1 <- lm(anteil_immun ~ tote_100k + bev_anteil_65plus + anteil_noaut 
          + bildung_anteil_hochschule + bld, data = sel_daten_trans)
summary(lm1)
```

**ü§î Was sehen wir hier?**

Vergleichen wir zun√§chst einmal die **Varianzaufkl√§rung** unserer beiden Modelle lm0 und lm1:

```{r vergleichRquad}
cbind(c("lm0", "lm1"), c(summary(lm0)$adj.r.squared, summary(lm1)$adj.r.squared))
```

Die Hinzunahme der Bundeslandzugeh√∂rigkeit hat also zu einer Verdoppelung der Varianzaufkl√§rung gef√ºhrt. Mit knapp 63% Varianzaufkl√§rung liegt unser Modell nicht schlecht (klar √ºber 50%), wenn auch noch deutlich Luft nach oben gegeben ist.

Kommen wir zu den **Regressionskoeffizienten**:

```{r coeffPlot}
coeff_lm1 <- as_tibble(summary(lm1)$coefficients, rownames = "erklaerende") %>%
  janitor::clean_names() %>%    # Spaltennamen bereinigen
  mutate(erklaerende = factor(erklaerende),   # in Faktor √ºberf√ºhren f√ºr Diagramm
         erklaerende = forcats::fct_reorder(erklaerende, estimate),  #Sortieren f√ºr Diagramm
         vis_sig = cut(pr_t, breaks = c(0, 0.05, 1), 
                       labels = c("signifikant (p<=0,05)", "nicht signifikant (p>0,05)")))  # Signifikanz als Faktor f√ºr Diagramm

ggplot(coeff_lm1, aes(x = erklaerende, y = estimate, fill = vis_sig)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Erkl√§rende Variablen\n",
       y = "\nRegressionskoeffizienten",
       fill = "Signifikanz")
```

Bei den metrischen Variablen sehen wir, dass der Anteil der HochschulabsolventInnen und der Anteil der √ºber 65-J√§hrigen signifikant positiv auf die Impfquote wirken. Die Mortalit√§t und der Anteil der Nicht-√ñsterreicherInnen w√ºrden negativ auf die Impfquote einwirken, wenn sie denn signifikant w√§ren. Bei unserer nominalen Bundeslandzugeh√∂rigkeit sehen wir, dass nur der Intercept - also die Konstante der Regressionsgleichung - klar positiv auf die Impfquote einwirkt. Und hier kn√ºpfen wir nochmals an die vorherigen Ausf√ºhrungen aus Kapitel \@ref(qualVaria) an: Dieser Intercept steht inhaltlich f√ºr die Linearkombination der acht verwendeten Dummy-Codes, also f√ºr das Bundesland Burgenland. Die Lage eines Bezirkes im Burgenland tr√§gt also signifikant zu einer Erh√∂hung der Impfquote. Alle restlichen Bundesl√§nder weisen negative Regressionskoeffizienten auf und verringern damit die Impfquote. Am deutlichsten in den Bundesl√§ndern Tirol, Salzburg, Ober√∂sterreich und K√§rnten.

### Modelloptimierung

Um unser Modell im Sinne von [Ockhams Razor](https://de.wikipedia.org/wiki/Ockhams_Rasiermesser) noch etwas schlanker zu gestalten, wollen wir noch die **nicht signifikanten metrischen Variablen entfernen**:

```{r lm2 ohne noAut}
lm2 <- lm(anteil_immun ~ tote_100k + bev_anteil_65plus 
          + bildung_anteil_hochschule + bld, data = sel_daten_trans)
summary(lm2)

```

Das Entfernen des Anteils der Nicht-√ñsterreicherInnen bewirkt, dass im Vergleich zu lm1 die Bundeslandzugeh√∂rigkeit zu Wien signifikant zu einer verringerten Impfquote beitr√§gt. Nennesswerte Verschiebungen in den Regressionskoeffizienten der Dummy-Variablen zur Bundeslandzugeh√∂rigkeit k√∂nnen wir aber nicht beobachten.

Bliebe noch die Mortalit√§t zu entfernen:

```{r lm3 ohne tote_100k}
lm3 <- lm(anteil_immun ~ bev_anteil_65plus + bildung_anteil_hochschule + bld, 
          data = sel_daten_trans)
summary(lm3)
```

**ü§î Was hat uns das Entfernen dieser beiden metrischen Variablen nun gebracht?**

Einerseits habt sich die Varianzaufkl√§rung unseres Modells dadurch graduell von knapp 63% auf 60% verschlechtert. Gleichzeitig konnten wir aber auch die Anzahl der erkl√§renden Variablen von f√ºnf auf drei reduzieren. Ein Tradeoff den wir hier einmal akzeptieren k√∂nnen: Mit fast der H√§lfte an Variablen nahezu die gleiche Varianzaufkl√§rung zu liefern, ist kein schlechter Deal üòâ

In Summe hat sich gezeigt, dass die Bundeslandzugeh√∂rigkeit unser urspr√ºnglich rein metrisches Modell deutlich verbessert hat. Die im Laufe unserer Analyse entfernten Variablen wie der Anteil der FP√ñ-W√§hlerInnen, die Corona-bedingte Mortalit√§t oder der Anteil der Nicht-√ñsterreicherInnen in den Bezirken erwiesen sich zur Erkl√§rung der bezirksweisen Impfquoten als nicht aussagekr√§ftig.

## Abschlie√üendes Pr√ºfen der Modellannahmen

Analog zu Kapitel \@ref(annahmen) wollen wir zuletzt noch √ºberpr√ºfen, ob unser Modell lm3 folgende Modellannahmen erf√ºllt:

1.  Linearer Zusammenhang gegeben

2.  Residuen = normalverteilt

3.  Erwartungswert der Residuen = 0

4.  Residuen haben konstante Varianz (Homoskedastizi√§t)

5.  Residuen sind unkorreliert zu Beobachtungen (Autokorrelation)

### Pr√ºfung des linearen Zusammenhangs

Anhand des **"Residuals vs. Fitted"-Plot** sehen wir, dass

-   kein klares Muster in der Punktverteilung ersichtlich ist;

-   und die Regressionslinie naher der Null-Linie zu liegen kommt.

```{r}
plot(lm3, 1, labels.id = sel_daten_trans$bez_txt)
```

Wir k√∂nnen also von einem linearen Zusammenhang ausgehen.

### Pr√ºfung der Normalverteilung der Residuen

Da die Residuen ja Abbild einer zuf√§lligen Streuung sein sollten, m√ºssten sie einer Normalverteilung folgen. Auch hier bietet R einen passenden Standard-Plot f√ºr lineare Modelle: Einen sgn. **"Q-Q Plot".** In unserem Fall sehen wir eine hinreichend gute Ann√§herung an eine Normalverteilung - also an die strichlierte Hauptdiagonale:

```{r}
plot(lm3, 2, labels.id = sel_daten_trans$bez_txt)
```

> **üìö Exkurs: ... Leverage one**
>
> Die Adleraugen haben sicherlich den Fehler im obigen Output erkannt: `Warning: not plotting observations with leverage one: 93`. Diese Fehlermeldung l√§sst sich in unserem Fall auf die Datenstruktur zur√ºckf√ºhren: Kategoriale Variablen bei denen ein Level nur mit einer Beobachtung besetzt sind, verursachen Probleme bei der Berechnung von Residuen. In unserem Fall trifft das auf den Bezirk Wien (Rekord Nr. 93), da er der einzige Bezirk im Bundesland Wien ist.\
> **Kurz und gut:** Aufgrund unserer speziellen Datenstruktur k√∂nnen wir diese Fehlermeldung ignorieren.

### Pr√ºfung des Erwartungswerts der Residuen

Der Erwartungswert (= Summe) der Residuen sollte bei 0 liegen. Um dies zu √ºberpr√ºfen:

```{r}
sum(residuals(lm3))
```

Jep, bei 15 Nullen nach dem Komma, k√∂nnen wir von einer hinreichenden Approximation von 0 ausgehen üòâ .

### Pr√ºfung der Konstanz der Varianz der Residuen ("Homoskedastizit√§t")

Im **Scale-Location-Plot** sehen wir ...

```{r message=FALSE, warning=FALSE}
plot(lm3, 3, labels.id = sel_daten_trans$bez_txt)
```

... einigerma√üen gleichm√§√üig √ºber die Fitted-Values verteilte Residuen (= ann√§hernd horizontal verlaufende Regressionsgerade). Wir k√∂nnen somit von einer **Homogenit√§t in den Varianzen** ("Homoskedastizit√§t") ausgehen.

### Pr√ºfung auf Autokorrelation

Eine weitere Annahme linearer Modelle ist die

Um final zu √ºberpr√ºfen, ob die **Unabh√§ngigkeit der Residuen von der Reihenfolge der Beobachtungen.** gegeben ist:

```{r}
ggplot(sel_daten_trans, aes(x=(1:length(bez_id)), y=residuals(lm3))) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x, se=F, color="red") +
  labs(x = "\nBeobachtungen", y = "Residuen\n") +
  theme_gray(base_size = 18)
```

Und wieder ist ein "Jep!" angebracht: Wir sehen in der Verteilung der Residuen √ºber die Beobachtungen keine auff√§lligen Muster, was auch durch die Lagen der Regressionsgeraden entlang der Nullline best√§tigt wird. Wir k√∂nnen also eine Autokorrelation ausschlie√üen.

------------------------------------------------------------------------

üèÜ **Nun wissen wir, ...**

-   wie wir direkt in R **Datenmanipulationen** wie die Transformation einer numerischen Variable in einen Faktor vornehmen k√∂nnen;
-   wie die **Dummy-Kodierung** von Faktoren in R abl√§uft;
-   wie wir **Visualisierungen** zur Interpretation von **Modellparametern** nutzen k√∂nnen;
-   dass die **Bundeslandzugeh√∂rigkeit** eines Bezirkseinen starken Beitrag zur Erkl√§rung der Impfquote liefert.

![](images/faszinierend.gif){.videoframe width="210"}

**Einfach faszinierend!**
